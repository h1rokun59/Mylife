name: Process Research Queue (Stepwise Worker)

on:
  workflow_run:
    workflows: ["Enqueue Research Requests"]
    types: [completed]
  schedule:
    - cron: "*/5 * * * *"
  workflow_dispatch:

concurrency:
  group: mylife-main-writes
  cancel-in-progress: false

jobs:
  process:
    if: github.repository == 'h1rokun59/Mylife' && (github.event_name != 'workflow_run' || github.event.workflow_run.conclusion == 'success')
    runs-on: ubuntu-latest

    permissions:
      contents: write

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: "Process queue (4-step + backward compatible, Normal/Heavy)"
        env:
          # Gemini
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          GEMINI_MODEL: gemini-2.5-flash
          GEMINI_THINKING_BUDGET: "-1"

          # OpenAI (optional)
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          OPENAI_MODEL: gpt-4.1

          # Anthropic (optional)
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          ANTHROPIC_MODEL: claude-sonnet-4-20250514
          ANTHROPIC_VERSION: "2023-06-01"

          # SOC repo outputs
          ROUTER_PAT: ${{ secrets.ROUTER_PAT }}
          SOC_OWNER: h1rokun59
          SOC_REPO_SLUG: soc-modernization
        run: |
          set -euo pipefail

          NOW_EPOCH="$(date -u +%s)"
          NOW_UTC="$(date -u +"%Y-%m-%dT%H:%M:%SZ")"
          echo "NOW_UTC=$NOW_UTC event=$GITHUB_EVENT_NAME repo=$GITHUB_REPOSITORY"

          PENDING_FILES=$(git ls-files 'research-queue/pending/*.json' || true)
          if [ -z "${PENDING_FILES}" ]; then
            echo "No pending queue files."
            exit 0
          fi

          mkdir -p research-results
          mkdir -p research-queue/processed

          processed_any=false
          SOC_CHANGED=false
          SOC_DIR="/tmp/${SOC_REPO_SLUG}"

          # NormalÔºàÁÑ°ÊñôÈÅãÁî®Ôºâ: 1 run 1 Gemini call
          GEMINI_CALLS_THIS_RUN=0

          # ---------- helpers ----------
          to_epoch() {
            local iso="$1"
            if [ -z "$iso" ] || [ "$iso" = "null" ]; then echo "0"; return; fi
            date -u -d "$iso" +%s 2>/dev/null || echo "0"
          }

          add_minutes() {
            local minutes="$1"
            date -u -d "${NOW_UTC} + ${minutes} minutes" +"%Y-%m-%dT%H:%M:%SZ"
          }

          is_pro_task() {
            local tagcsv="$1"
            echo ",$tagcsv," | grep -qiE ',(resilience|soc|threat-intel|cloud|ai-ml|architecture|people|process),'
          }

          ensure_soc_repo() {
            if [ -d "${SOC_DIR}/.git" ]; then return 0; fi
            if [ -z "${ROUTER_PAT:-}" ]; then
              echo "ROUTER_PAT is not set. Cannot write to SOC repo."
              exit 2
            fi
            echo "Cloning SOC repo..."
            git clone "https://x-access-token:${ROUTER_PAT}@github.com/${SOC_OWNER}/${SOC_REPO_SLUG}.git" "${SOC_DIR}"
          }

          read_ctx_file() {
            local rel="$1"
            local p="${SOC_DIR}/${rel}"
            if [ -f "$p" ]; then head -c 12000 "$p"; else echo ""; fi
          }

          step_file() {
            local step="$1"
            case "$step" in
              step1) echo "01-step1.md" ;;
              step2) echo "02-step2.md" ;;
              step3) echo "03-step3.md" ;;
              step4) echo "04-step4.md" ;;
              *) echo "00-unknown.md" ;;
            esac
          }

          extract_idea_body() {
            local path="$1"
            if [ -z "$path" ] || [ ! -f "$path" ]; then echo ""; return; fi
            awk '
              /^---$/ { next }
              /^\*Captured via Idea Capture App\*$/ { next }
              /^# / { next }
              /^\*\*[A-Za-z0-9-]+:\*\* / { next }
              { print }
            ' "$path"
          }

          # stepsÈÖçÂàó„ÇíË™≠„Åø„ÄÅcurrent_step„ÅÆÊ¨°„ÇíË®àÁÆó
          load_steps() {
            local qfile="$1"
            mapfile -t STEPS < <(jq -r '(.methodology.steps // ["step1","step2","step3"])[]' "$qfile")
          }

          index_of_step() {
            local needle="$1"
            local i=0
            for s in "${STEPS[@]}"; do
              if [ "$s" = "$needle" ]; then echo "$i"; return 0; fi
              i=$((i+1))
            done
            echo "-1"
            return 0
          }

          get_next_step() {
            local step="$1"
            local idx
            idx="$(index_of_step "$step")"
            if [ "$idx" -lt 0 ]; then
              echo ""
              return 0
            fi
            local next_idx=$((idx+1))
            if [ "$next_idx" -ge "${#STEPS[@]}" ]; then
              echo ""
              return 0
            fi
            echo "${STEPS[$next_idx]}"
          }

          read_step_output() {
            local out_dir="$1"
            local step="$2"
            local f="${out_dir}/$(step_file "$step")"
            if [ -f "$f" ]; then head -c 12000 "$f"; else echo ""; fi
          }

          # ---------- LLM callers ----------
          gemini_generate() {
            local prompt="$1"
            if [ -z "${GEMINI_API_KEY:-}" ]; then
              echo "__ERROR__: GEMINI_API_KEY is not set"
              return 2
            fi

            local req
            req="$(jq -n \
              --arg p "$prompt" \
              --argjson b "${GEMINI_THINKING_BUDGET:--1}" \
              '{
                contents: [{ role: "user", parts: [{ text: $p }] }],
                generationConfig: { thinkingConfig: { thinkingBudget: $b } }
              }')"

            local resp
            resp="$(curl -sS \
              -H "x-goog-api-key: ${GEMINI_API_KEY}" \
              -H "Content-Type: application/json" \
              -X POST \
              "https://generativelanguage.googleapis.com/v1beta/models/${GEMINI_MODEL:-gemini-2.5-flash}:generateContent" \
              -d "$req")" || { echo "__ERROR__: curl failed"; return 3; }

            if echo "$resp" | jq -e '.error' >/dev/null 2>&1; then
              echo "__ERROR__: $(echo "$resp" | jq -r '.error.message // "unknown error"')"
              return 4
            fi

            local text
            text="$(echo "$resp" | jq -r '[.candidates[0].content.parts[]?.text] | join("\n")' 2>/dev/null || true)"
            if [ -z "$text" ] || [ "$text" = "null" ]; then
              echo "__ERROR__: empty response text"
              return 5
            fi
            printf '%s' "$text"
          }

          openai_generate() {
            local prompt="$1"
            if [ -z "${OPENAI_API_KEY:-}" ]; then
              echo "__ERROR__: OPENAI_API_KEY is not set"
              return 2
            fi

            local req
            req="$(jq -n --arg m "${OPENAI_MODEL:-gpt-4.1}" --arg p "$prompt" '{model:$m,input:$p}')"

            local resp
            resp="$(curl -sS https://api.openai.com/v1/responses \
              -H "Content-Type: application/json" \
              -H "Authorization: Bearer ${OPENAI_API_KEY}" \
              -d "$req")" || { echo "__ERROR__: curl failed"; return 3; }

            if echo "$resp" | jq -e '.error' >/dev/null 2>&1; then
              echo "__ERROR__: $(echo "$resp" | jq -r '.error.message // "unknown error"')"
              return 4
            fi

            local text
            text="$(echo "$resp" | jq -r '.output_text // ([.output[]?.content[]?.text] | join("\n"))' 2>/dev/null || true)"
            if [ -z "$text" ] || [ "$text" = "null" ]; then
              echo "__ERROR__: empty response text"
              return 5
            fi
            printf '%s' "$text"
          }

          anthropic_generate() {
            local prompt="$1"
            if [ -z "${ANTHROPIC_API_KEY:-}" ]; then
              echo "__ERROR__: ANTHROPIC_API_KEY is not set"
              return 2
            fi

            local req
            req="$(jq -n \
              --arg m "${ANTHROPIC_MODEL:-claude-sonnet-4-20250514}" \
              --arg p "$prompt" \
              '{model:$m,max_tokens:2048,messages:[{role:"user",content:$p}] }')"

            local resp
            resp="$(curl -sS https://api.anthropic.com/v1/messages \
              --header "x-api-key: ${ANTHROPIC_API_KEY}" \
              --header "anthropic-version: ${ANTHROPIC_VERSION:-2023-06-01}" \
              --header "content-type: application/json" \
              --data "$req")" || { echo "__ERROR__: curl failed"; return 3; }

            if echo "$resp" | jq -e '.error' >/dev/null 2>&1; then
              echo "__ERROR__: $(echo "$resp" | jq -r '.error.message // "unknown error"')"
              return 4
            fi

            local text
            text="$(echo "$resp" | jq -r '[.content[]?.text] | join("\n")' 2>/dev/null || true)"
            if [ -z "$text" ] || [ "$text" = "null" ]; then
              echo "__ERROR__: empty response text"
              return 5
            fi
            printf '%s' "$text"
          }

          pick_orchestrator() {
            if [ -n "${ANTHROPIC_API_KEY:-}" ]; then echo "claude"; return; fi
            if [ -n "${OPENAI_API_KEY:-}" ]; then echo "chatgpt"; return; fi
            echo "gemini"
          }

          run_provider() {
            local provider="$1"
            local prompt="$2"
            local outfile="$3"

            set +e
            case "$provider" in
              gemini) out="$(gemini_generate "$prompt")"; rc=$? ;;
              chatgpt) out="$(openai_generate "$prompt")"; rc=$? ;;
              claude) out="$(anthropic_generate "$prompt")"; rc=$? ;;
              *) out="__ERROR__: unknown provider $provider"; rc=99 ;;
            esac
            set -e

            mkdir -p "$(dirname "$outfile")"
            if [ $rc -ne 0 ] || echo "$out" | grep -q '^__ERROR__:'; then
              printf "%s\n" "$out" > "$outfile"
              return 1
            fi
            printf "%s\n" "$out" > "$outfile"
            return 0
          }

          heavy_parallel_stage() {
            local prompt="$1"
            local outdir="$2"
            shift 2
            local providers=("$@")

            mkdir -p "$outdir"
            pids=()
            for pr in "${providers[@]}"; do
              run_provider "$pr" "$prompt" "${outdir}/${pr}.md" &
              pids+=($!)
            done

            fail=0
            for pid in "${pids[@]}"; do
              wait "$pid" || fail=1
            done
            return $fail
          }

          push_soc_repo() {
            local msg="$1"
            if [ "$SOC_CHANGED" != "true" ]; then return 0; fi

            git -C "${SOC_DIR}" config user.email "actions@github.com"
            git -C "${SOC_DIR}" config user.name "GitHub Actions"
            git -C "${SOC_DIR}" add research-results 2>/dev/null || true
            git -C "${SOC_DIR}" commit -m "$msg" || echo "Nothing to commit in SOC."

            for i in 1 2 3; do
              git -C "${SOC_DIR}" fetch origin main
              if git -C "${SOC_DIR}" rebase origin/main; then
                if git -C "${SOC_DIR}" push; then
                  echo "SOC push succeeded."
                  return 0
                fi
              else
                git -C "${SOC_DIR}" rebase --abort || true
              fi
              sleep $((i * 2))
            done
            echo "SOC push failed after retries."
            return 1
          }

          # ---------- main loop ----------
          while IFS= read -r qfile; do
            [ -z "$qfile" ] && continue
            [ ! -f "$qfile" ] && continue

            echo "----------------------------------------"
            echo "Queue: $qfile"

            IDEA_ID=$(jq -r '.idea_id // ""' "$qfile")
            STATUS=$(jq -r '.status // ""' "$qfile")

            MODE=$(jq -r '.execution.mode // "normal"' "$qfile")
            ONE_STEP_PER_RUN=$(jq -r '.execution.one_step_per_run // true' "$qfile")
            COOLDOWN_MIN=$(jq -r '.execution.cooldown_minutes_between_steps // 15' "$qfile")

            CUR_STEP=$(jq -r '.state.current_step // "step1"' "$qfile")
            NEXT_ELIGIBLE=$(jq -r '.state.next_eligible_at_utc // ""' "$qfile")

            TITLE=$(jq -r '.idea.title // ""' "$qfile")
            TAG_KEYS=$(jq -r '(.idea.tag_keys // []) | join(",")' "$qfile")
            ACTIONS=$(jq -r '(.idea.actions // []) | join(",")' "$qfile")

            SOURCE_URL=$(jq -r '.source.url // ""' "$qfile")
            SOURCE_PATH=$(jq -r '.source.path // ""' "$qfile")

            if [ -z "$IDEA_ID" ]; then IDEA_ID="$(basename "$qfile" .json)"; fi
            if [ "$STATUS" != "pending" ]; then continue; fi

            NEXT_EPOCH="$(to_epoch "$NEXT_ELIGIBLE")"
            if [ "$NEXT_EPOCH" -gt "$NOW_EPOCH" ]; then
              echo "Skip: not eligible yet. next_eligible_at_utc=$NEXT_ELIGIBLE"
              continue
            fi

            load_steps "$qfile"

            # target decision
            TARGET="mylife"
            if [ "$MODE" = "super-heavy" ] || is_pro_task "$TAG_KEYS"; then
              TARGET="soc"
              ensure_soc_repo
            fi

            OUT_DIR="research-results/${IDEA_ID}"
            if [ "$TARGET" = "soc" ]; then
              OUT_DIR="${SOC_DIR}/research-results/${IDEA_ID}"
            fi
            mkdir -p "$OUT_DIR"

            IDEA_BODY="$(extract_idea_body "$SOURCE_PATH")"

            # Build base context (SOC only)
            CTX=""
            if [ "$TARGET" = "soc" ]; then
              CTX_MUST="$(read_ctx_file 'research-context/00-MUST-READ.md')"
              CTX_DATA="$(read_ctx_file 'research-context/10-data-handling.md')"
              CTX_GUARD="$(read_ctx_file 'research-context/20-research-guardrails.md')"
              CTX_OUTT="$(read_ctx_file 'research-context/30-output-template.md')"
              CTX_BG="$(read_ctx_file 'research-context/background.md')"
              CTX_ORG="$(read_ctx_file 'research-context/40-org-context-sanitized.md')"
              CTX_TOOL="$(read_ctx_file 'research-context/50-tool-landscape-candidates.md')"
              CTX="$(printf '%s\n\n%s\n\n%s\n\n%s\n\n%s\n\n%s\n\n%s\n' \
                "$CTX_MUST" "$CTX_DATA" "$CTX_GUARD" "$CTX_OUTT" "$CTX_BG" "$CTX_ORG" "$CTX_TOOL")"
            fi

            # Decide steps to run
            steps_to_run=()
            if [ "$MODE" = "super-heavy" ] && [ "$ONE_STEP_PER_RUN" = "false" ]; then
              idx="$(index_of_step "$CUR_STEP")"
              [ "$idx" -lt 0 ] && idx=0
              for ((k=idx; k<${#STEPS[@]}; k++)); do steps_to_run+=("${STEPS[$k]}"); done
            else
              steps_to_run+=("$CUR_STEP")
            fi

            echo "Target=$TARGET Mode=$MODE current_step=$CUR_STEP steps_to_run=${steps_to_run[*]}"
            steps_done_csv=""

            # Heavy providers (only those with keys)
            allowed_csv="$(jq -r '(.execution.providers.allowed // []) | join(",")' "$qfile")"
            [ -z "$allowed_csv" ] && allowed_csv="gemini,claude,chatgpt"
            PROVIDERS=()
            echo ",$allowed_csv," | grep -qi ",gemini," && [ -n "${GEMINI_API_KEY:-}" ] && PROVIDERS+=("gemini")
            echo ",$allowed_csv," | grep -qi ",chatgpt," && [ -n "${OPENAI_API_KEY:-}" ] && PROVIDERS+=("chatgpt")
            echo ",$allowed_csv," | grep -qi ",claude," && [ -n "${ANTHROPIC_API_KEY:-}" ] && PROVIDERS+=("claude")
            ORCH="$(pick_orchestrator)"

            for s in "${steps_to_run[@]}"; do
              sf="$(step_file "$s")"
              step_path="${OUT_DIR}/${sf}"

              # Step-specific instruction (SOC only)
              STEP_INST=""
              if [ "$TARGET" = "soc" ]; then
                # 4-step documents exist (your step‚ë† done)
                case "$s" in
                  step1) STEP_INST="$(read_ctx_file 'research-context/4step/step1-design.md')" ;;
                  step2) STEP_INST="$(read_ctx_file 'research-context/4step/step2-execute.md')" ;;
                  step3) STEP_INST="$(read_ctx_file 'research-context/4step/step3-redteam.md')" ;;
                  step4) STEP_INST="$(read_ctx_file 'research-context/4step/step4-decision.md')" ;;
                  *) STEP_INST="" ;;
                esac

                # legacy 3-step fallback if empty
                if [ -z "$STEP_INST" ]; then
                  case "$s" in
                    step1) STEP_INST="$(read_ctx_file 'research-context/3step/step1-instructions.md')" ;;
                    step2) STEP_INST="$(read_ctx_file 'research-context/3step/step2-instructions.md')" ;;
                    step3) STEP_INST="$(read_ctx_file 'research-context/3step/step3-instructions.md')" ;;
                    *) STEP_INST="" ;;
                  esac
                fi
              fi

              PREV_INPUT=""
              if [ "$s" != "step1" ]; then
                for prev in "${STEPS[@]}"; do
                  [ "$prev" = "$s" ] && break
                  txt="$(read_step_output "$OUT_DIR" "$prev")"
                  if [ -n "$txt" ]; then
                    PREV_INPUT="${PREV_INPUT}\n\n--- ${prev} Output ---\n${txt}"
                  fi
                done
              fi

              if [ "$MODE" = "normal" ]; then
                # Normal = Gemini, 1 call/run
                if [ "$GEMINI_CALLS_THIS_RUN" -ge 1 ]; then
                  echo "Skip: Gemini call limit reached for this run (1 call)."
                  continue 2
                fi

                PROMPT="$(
                  {
                    printf '%s\n' "„ÅÇ„Å™„Åü„ÅØ4StepË™øÊüª„Éó„É≠„Çª„Çπ„ÅÆ ${s} „ÇíÂÆüÊñΩ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ"
                    printf '%s\n' "Âà∂Á¥Ñ: Â§ñÈÉ®WebÊ§úÁ¥¢„Å™„Åó / Markdown„ÅÆ„Åø / Ê©üÂØÜ„ÉªÂõ∫ÊúâÂêçË©û„ÉªÂÄã‰∫∫ÊÉÖÂ†±„ÅØÊäΩË±°Âåñ / Êú™Á¢∫Ë™ç„ÅØÊú™Á¢∫Ë™ç„Å®Êõ∏„Åè"
                    printf '\n'
                    if [ -n "$CTX" ]; then
                      printf '%s\n' '--- Context Pack (MUST READ) ---'
                      printf '%s\n' "$CTX"
                      printf '\n'
                    fi
                    if [ -n "$STEP_INST" ]; then
                      printf '%s\n' '--- Step Instruction ---'
                      printf '%s\n' "$STEP_INST"
                      printf '\n'
                    fi
                    printf '%s\n' 'ÂÖ•Âäõ:'
                    printf '%s\n' "- Title: ${TITLE}"
                    printf '%s\n' "- TagKeys: ${TAG_KEYS}"
                    printf '%s\n' "- Actions: ${ACTIONS}"
                    printf '%s\n' "- Source: ${SOURCE_URL}"
                    printf '\n'
                    if [ -n "$PREV_INPUT" ]; then
                      printf '%s\n' "$PREV_INPUT"
                      printf '\n'
                    fi
                    printf '%s\n' '--- Original Idea Body ---'
                    printf '%s\n' "${IDEA_BODY}"
                  }
                )"

                echo "Calling Gemini for ${s} (normal)..."
                GEMINI_CALLS_THIS_RUN=$((GEMINI_CALLS_THIS_RUN + 1))

                set +e
                OUT="$(gemini_generate "$PROMPT")"
                RC=$?
                set -e

                mkdir -p "$(dirname "$step_path")"
                if [ $RC -ne 0 ] || echo "$OUT" | grep -q '^__ERROR__:'; then
                  printf '%s\n' "# üß© ${s} (Gemini ERROR)" > "$step_path"
                  printf '%s\n' "$OUT" >> "$step_path"
                  processed_any=true
                  [ "$TARGET" = "soc" ] && SOC_CHANGED=true
                  continue 2
                fi

                {
                  printf '# üß© %s (Gemini Thinking)\n\n' "$s"
                  printf '**Idea-ID:** %s\n' "$IDEA_ID"
                  printf '**Mode:** %s\n' "$MODE"
                  printf '**Target:** %s\n' "$TARGET"
                  printf '**Ran-At-UTC:** %s\n\n' "$NOW_UTC"
                  printf '%s\n' "$OUT"
                } > "$step_path"

                [ "$TARGET" = "soc" ] && SOC_CHANGED=true

              else
                # Heavy = parallel providers + orchestrator synthesis
                if [ "${#PROVIDERS[@]}" -eq 0 ]; then
                  echo "No providers available for heavy (missing API keys)."
                  exit 3
                fi

                RAW_DIR="${OUT_DIR}/heavy/raw/${s}"
                PROMPT="$(
                  {
                    printf '%s\n' "„ÅÇ„Å™„Åü„ÅØ${s}„ÇíÂÆüÊñΩ„Åó„Å¶„Åè„Å†„Åï„ÅÑÔºàÂ§ñÈÉ®WebÊ§úÁ¥¢„Å™„Åó/Markdown„ÅÆ„Åø/Ê©üÂØÜÊäΩË±°Âåñ/Êú™Á¢∫Ë™ç„ÅØÊú™Á¢∫Ë™çÔºâ„ÄÇ"
                    printf '\n'
                    if [ -n "$CTX" ]; then
                      printf '%s\n' '--- Context Pack (MUST READ) ---'
                      printf '%s\n' "$CTX"
                      printf '\n'
                    fi
                    if [ -n "$STEP_INST" ]; then
                      printf '%s\n' '--- Step Instruction ---'
                      printf '%s\n' "$STEP_INST"
                      printf '\n'
                    fi
                    printf '%s\n' 'ÂÖ•Âäõ:'
                    printf '%s\n' "- Title: ${TITLE}"
                    printf '%s\n' "- TagKeys: ${TAG_KEYS}"
                    printf '%s\n' "- Actions: ${ACTIONS}"
                    printf '%s\n' "- Source: ${SOURCE_URL}"
                    printf '\n'
                    if [ -n "$PREV_INPUT" ]; then
                      printf '%s\n' "$PREV_INPUT"
                      printf '\n'
                    fi
                    printf '%s\n' '--- Original Idea Body ---'
                    printf '%s\n' "${IDEA_BODY}"
                  }
                )"

                echo "Heavy parallel ${s}: providers=${PROVIDERS[*]} orchestrator=${ORCH}"
                heavy_parallel_stage "$PROMPT" "$RAW_DIR" "${PROVIDERS[@]}" || true

                SYNTH_PROMPT="$(
                  {
                    printf '%s\n' "„ÅÇ„Å™„Åü„ÅØHeavy„É¢„Éº„Éâ„ÅÆË¶™ÊñπÔºàorchestratorÔºâ„Åß„Åô„ÄÇ‰ª•‰∏ã„ÅÆË§áÊï∞„É¢„Éá„É´Âá∫Âäõ„ÇíÁµ±Âêà„Åó„ÄÅ${s} „ÅÆÊúÄÁµÇ„Ç¢„Ç¶„Éà„Éó„ÉÉ„Éà„Çí‰ΩúÊàê„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ"
                    printf '%s\n' 'Âà∂Á¥Ñ: Markdown„ÅÆ„Åø / Ê©üÂØÜÊäΩË±°Âåñ / Êú™Á¢∫Ë™ç„ÅØÊú™Á¢∫Ë™ç„Å®ÊòéË®ò / ‰ΩôË®à„Å™ÂâçÁΩÆ„Åç‰∏çË¶Å'
                    printf '\n'
                    printf '%s\n' '--- Inputs (raw model outputs) ---'
                    for pr in "${PROVIDERS[@]}"; do
                      printf '%s\n' "## Provider: ${pr}"
                      if [ -f "${RAW_DIR}/${pr}.md" ]; then head -c 12000 "${RAW_DIR}/${pr}.md"; else printf '%s\n' '(missing)'; fi
                      printf '\n'
                    done
                    printf '%s\n' '---'
                    printf '%s\n' 'Âá∫Âäõ„ÅØStep Instruction„ÅÆ„ÉÜ„É≥„Éó„É¨„Å´Âæì„Å£„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ'
                  }
                )"

                set +e
                case "$ORCH" in
                  claude) OUT_SYNTH="$(anthropic_generate "$SYNTH_PROMPT")"; RC=$? ;;
                  chatgpt) OUT_SYNTH="$(openai_generate "$SYNTH_PROMPT")"; RC=$? ;;
                  gemini) OUT_SYNTH="$(gemini_generate "$SYNTH_PROMPT")"; RC=$? ;;
                  *) OUT_SYNTH="__ERROR__: unknown orchestrator"; RC=99 ;;
                esac
                set -e

                mkdir -p "$(dirname "$step_path")"
                if [ $RC -ne 0 ] || echo "$OUT_SYNTH" | grep -q '^__ERROR__:'; then
                  printf '%s\n' "# üß© ${s} (HEAVY synth ERROR)" > "$step_path"
                  printf '%s\n' "$OUT_SYNTH" >> "$step_path"
                  processed_any=true
                  [ "$TARGET" = "soc" ] && SOC_CHANGED=true
                  continue 2
                fi

                {
                  printf '# üß© %s (HEAVY)\n\n' "$s"
                  printf '**Idea-ID:** %s\n' "$IDEA_ID"
                  printf '**Mode:** %s\n' "$MODE"
                  printf '**Target:** %s\n' "$TARGET"
                  printf '**Orchestrator:** %s\n' "$ORCH"
                  printf '**Providers Used:** %s\n' "${PROVIDERS[*]}"
                  printf '**Ran-At-UTC:** %s\n\n' "$NOW_UTC"
                  printf '%s\n' "$OUT_SYNTH"
                  printf '\n---\nRaw outputs: heavy/raw/%s/{provider}.md\n' "$s"
                } > "$step_path"

                [ "$TARGET" = "soc" ] && SOC_CHANGED=true
              fi

              # mark done
              if [ -z "$steps_done_csv" ]; then steps_done_csv="$s"; else steps_done_csv="${steps_done_csv},$s"; fi
            done

            # compute next step from last step executed
            LAST_DONE="${steps_to_run[-1]}"
            NEXT_STEP="$(get_next_step "$LAST_DONE")"

            if [ -z "$NEXT_STEP" ]; then
              # done -> processed
              PROCESSED_Q="research-queue/processed/${IDEA_ID}.json"

              RESULT_REPO="$GITHUB_REPOSITORY"
              RESULT_DIR="research-results/${IDEA_ID}"
              if [ "$TARGET" = "soc" ]; then
                RESULT_REPO="${SOC_OWNER}/${SOC_REPO_SLUG}"
                RESULT_DIR="research-results/${IDEA_ID}"
              fi

              # final.md pointer
              FINAL_PATH="${OUT_DIR}/final.md"
              {
                printf '# ‚úÖ Research Result (Final)\n\n'
                printf '**Idea-ID:** %s\n' "$IDEA_ID"
                printf '**Mode:** %s\n' "$MODE"
                printf '**Target:** %s\n' "$TARGET"
                printf '**Completed-At-UTC:** %s\n\n' "$NOW_UTC"
                printf 'Steps:\n'
                for st in "${STEPS[@]}"; do printf '- %s\n' "$(step_file "$st")"; done
                printf '\n'
                if [ "$MODE" = "super-heavy" ]; then
                  printf 'Raw:\n'
                  for st in "${STEPS[@]}"; do printf '- heavy/raw/%s/\n' "$st"; done
                fi
              } > "$FINAL_PATH"
              [ "$TARGET" = "soc" ] && SOC_CHANGED=true

              jq \
                --arg processed_at_utc "$NOW_UTC" \
                --arg result_repo "$RESULT_REPO" \
                --arg result_dir "$RESULT_DIR" \
                --arg steps_done "$steps_done_csv" \
                '
                .status="done"
                | .state.status="done"
                | .state.current_step=null
                | .state.next_eligible_at_utc=null
                | .state.last_run_at_utc=$processed_at_utc
                | .state.completed_steps = ((.state.completed_steps // []) + ($steps_done | split(",") | map(select(length>0))) | unique)
                | .process={ processed_at_utc:$processed_at_utc, worker:{name:"github-actions-stepwise-worker",version:8}, mode:"steps-driven" }
                | .result={ repo:$result_repo, dir:$result_dir }
                ' "$qfile" > "$PROCESSED_Q"

              git rm -f "$qfile"
              processed_any=true

            else
              next_eligible="$NOW_UTC"
              if [ "$COOLDOWN_MIN" != "0" ] && [ "$COOLDOWN_MIN" != "null" ]; then
                next_eligible="$(add_minutes "$COOLDOWN_MIN")"
              fi

              tmp="/tmp/${IDEA_ID}.json"
              jq \
                --arg now "$NOW_UTC" \
                --arg next_step "$NEXT_STEP" \
                --arg next_eligible "$next_eligible" \
                --arg steps_done "$steps_done_csv" \
                '
                .status="pending"
                | .state.status="queued"
                | .state.current_step=$next_step
                | .state.next_eligible_at_utc=$next_eligible
                | .state.last_run_at_utc=$now
                | .state.completed_steps = ((.state.completed_steps // []) + ($steps_done | split(",") | map(select(length>0))) | unique)
                ' "$qfile" > "$tmp"

              mv "$tmp" "$qfile"
              processed_any=true
            fi

          done <<< "$PENDING_FILES"

          if [ "$processed_any" != "true" ]; then
            echo "No eligible queue items processed."
            exit 0
          fi

          if [ "$SOC_CHANGED" = "true" ]; then
            push_soc_repo "üîé update research results (4-step)"
          fi

          if [ -z "$(git status --porcelain -- research-queue research-results)" ]; then
            echo "No Mylife changes to commit."
            exit 0
          fi

          git config user.email "actions@github.com"
          git config user.name "GitHub Actions"
          git add research-queue research-results
          git commit -m "ü§ñ process research queue (steps-driven 4-step)" || echo "Nothing to commit."

          for i in 1 2 3; do
            git fetch origin main
            if git rebase origin/main; then
              if git push; then
                echo "Mylife push succeeded."
                break
              fi
            else
              git rebase --abort || true
            fi
            sleep $((i * 2))
          done